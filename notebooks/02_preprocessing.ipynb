{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0674b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50f2cd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "\n",
    "train_data = pd.read_csv('../data/train.csv')\n",
    "test_data = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4963c854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating lable and features\n",
    "\n",
    "X_train = train_data.drop(columns= 'SalePrice')\n",
    "y_train = train_data['SalePrice']\n",
    "X_test = test_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0ad83af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking the logarithm of the lable column due to skewness\n",
    "\n",
    "y_train = np.log1p(train_data['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4531743d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns: ['Alley', 'MasVnrType', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature']\n"
     ]
    }
   ],
   "source": [
    "# Remove columns with a percentage of missing values ​​greater than 40\n",
    "\n",
    "missing_values_Percentage = train_data.isnull().mean() * 100\n",
    "columns_to_drop = missing_values_Percentage[missing_values_Percentage > 40].index\n",
    "train_data = train_data.drop(columns=columns_to_drop)\n",
    "test_data = test_data.drop(columns=columns_to_drop)\n",
    "print(f\"Dropped columns: {list(columns_to_drop)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e898f9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numeric and categorical columns\n",
    "\n",
    "num_cols = X_train.select_dtypes(include=[np.number]).columns\n",
    "cat_cols = X_train.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ea52792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric pipeline: impute missing values with median\n",
    "\n",
    "num_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f3e74e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical pipeline: impute with most frequent value, then one-hot encode\n",
    "\n",
    "cat_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', drop='first'))\n",
    "])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbe6eb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine both pipelines into a single preprocessor\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', num_pipeline, num_cols),\n",
    "    ('cat', cat_pipeline, cat_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdb77392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit on train, transform train and test\n",
    "\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c11ea1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: 84 / 245\n"
     ]
    }
   ],
   "source": [
    "# Train LassoCV on preprocessed data\n",
    "\n",
    "lasso = LassoCV(cv=5, random_state=42, n_jobs=-1)\n",
    "lasso.fit(X_train_processed, y_train)\n",
    "\n",
    "# Get mask of important features (non-zero coefficients)\n",
    "\n",
    "feature_mask = np.abs(lasso.coef_) > 1e-5\n",
    "selected_features = feature_mask.sum()\n",
    "\n",
    "print(f\"Selected features: {selected_features} / {X_train_processed.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2b7bfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_selected = X_train_processed[:, feature_mask]\n",
    "X_test_selected = X_test_processed[:, feature_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16035bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/processed/y_train.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load preprocessed data\n",
    "\n",
    "joblib.dump(X_train_selected, '../data/processed/X_train_selected.pkl')\n",
    "joblib.dump(X_test_selected, '../data/processed/X_test_selected.pkl')\n",
    "joblib.dump(y_train, '../data/processed/y_train.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faradars",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
